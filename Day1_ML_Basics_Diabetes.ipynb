{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Introduction\n",
        "In this session, we’ll explore a simple medical dataset that contains information about individuals, including their age, blood pressure, glucose levels, and more. Some of these people were diagnosed with diabetes, and some were not.\n",
        "\n",
        "Objective: Build a machine learning model to predict whether a person has diabetes based on their health measurements. Learn ML concepts like training, testing, accuracy, and how models make predictions.\n"
      ],
      "metadata": {
        "id": "SppD2UBffCca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Used: Pima Indians Diabetes Dataset\n",
        "This dataset is used to predict the onset of diabetes based on diagnostic health measurements. It contains medical data from female patients of Pima Indian heritage, aged 21 and above.\n",
        "\n",
        "---\n",
        "\n",
        "| Feature Name               | Description                                                                 |\n",
        "|---------------------------|-----------------------------------------------------------------------------|\n",
        "| **Pregnancies**           | Number of times the patient has been pregnant                              |\n",
        "| **Glucose**               | Plasma glucose concentration (mg/dL)                                       |\n",
        "| **BloodPressure**         | Diastolic blood pressure (mm Hg)                                           |\n",
        "| **SkinThickness**         | Triceps skinfold thickness (mm)                                            |\n",
        "| **Insulin**               | 2-Hour serum insulin level (mu U/ml)                                       |\n",
        "| **BMI**                   | Body Mass Index (weight in kg / (height in m)^2)                           |\n",
        "| **DiabetesPedigreeFunction** | Likelihood of diabetes based on family history                            |\n",
        "| **Age**                   | Age of the patient (years)                                                 |\n",
        "| **Outcome**               | Target variable (0 = No diabetes, 1 = Has diabetes)                         |\n"
      ],
      "metadata": {
        "id": "Lk49ve7sYMyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ML Pipeline Overview\n",
        "Data → Preprocessing → Train/Test Split → Model Training → Evaluation → Prediction\n",
        "\n",
        " ![ML Pipeline](https://github.com/sanjayksau/wmle2024/blob/main/ml_pipeline.png?raw=true)"
      ],
      "metadata": {
        "id": "ouEfZp38fIx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Library Imports"
      ],
      "metadata": {
        "id": "yhmU-Z4xSbf_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCTR_wzwdT24"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "# numpy: python library for numeric computation\n",
        "# pandas: library for data analysis and handling structured data (tabular data here)\n",
        "# matplotlib: a basic plotting library\n",
        "# seaborn: a more powerful plotting library for creating attractive graphs\n",
        "# scikit-learn(sklearn): a machine learning library (ready to use models, evaluation etc)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load Dataset"
      ],
      "metadata": {
        "id": "LUvS2QHzSWtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = \"https://raw.githubusercontent.com/plotly/datasets/master/diabetes.csv\"\n",
        "url = \"https://raw.githubusercontent.com/sanjayksau/BioML/refs/heads/main/diabetes.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "H_eiyvL8daID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Exploratory Data Analysis\n",
        "Exploratory Data Analysis (EDA) helps understand the data's structure, spot patterns, and detect issues like missing values or outliers — ensuring better model preparation and insights."
      ],
      "metadata": {
        "id": "Sr6UFAEiSiun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "#print(df.head())\n",
        "df.head()"
      ],
      "metadata": {
        "id": "1qg638Rcdci1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "#print(\"\\nMissing values:\")\n",
        "#print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "NsZjZeKkRIvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target variable distribution\n",
        "sns.countplot(x='Outcome', data=df)\n",
        "plt.title(\"Target Distribution (0 = No Diabetes, 1 = Diabetes)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LTOQ6N8xdfBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pairplot of a few features\n",
        "sns.pairplot(df[['Glucose', 'BMI', 'Age', 'Insulin', 'Outcome']], hue='Outcome', height=1.4, aspect=1.2)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Before building a model, pairplots offer intuitive visual understanding of:\n",
        "# Feature distributions\n",
        "# Class separability\n",
        "# Redundancy: Highly correlated features might be redundant for modeling.\n",
        "\n",
        "# You can infer how well-separated these two classes are across different feature combinations.\n",
        "# For example, if diabetic and non-diabetic dots are visibly separated in a scatterplot (like Glucose vs. BMI),\n",
        "# that feature pair is a good discriminator.\n",
        "# You can compare the distribution of glucose levels between diabetic and non-diabetic individuals\n",
        "# — diabetic ones likely show a higher peak at high glucose.\n",
        "# Isolated points away from the cluster may be outliers.\n",
        "# For example, someone with a BMI of 60 could be flagged for review.\n",
        "# Features where the two classes are most separated (e.g., Glucose, BMI) are more informative.\n",
        "\n",
        "# the diagonal shows univariate plots—that is, the distribution of individual features, one at a time.\n",
        "# Since hue is specified (e.g., diabetic vs. non-diabetic), it shows separate distributions for each class in different colors.\n"
      ],
      "metadata": {
        "id": "PLCXMdAcdkZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Data Preprocessing"
      ],
      "metadata": {
        "id": "FDRmNIDmSvA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#columns with zeros\n",
        "zero_counts = (df == 0).sum()\n",
        "columns_with_zeros = zero_counts[zero_counts > 0]\n",
        "print(columns_with_zeros)"
      ],
      "metadata": {
        "id": "XTfMEoGHSd1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Some columns have biologically implausible values (e.g., zero insulin or zero BMI).\n",
        "#Imputing missing values (mean, median, or model-based imputation)\n",
        "cols_with_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "\n",
        "for col in cols_with_zeros:\n",
        "    # Calculate mean excluding zero values\n",
        "    mean_value = df[df[col] != 0][col].mean()\n",
        "\n",
        "    # Replace 0 with the mean\n",
        "    df[col] = df[col].replace(0, mean_value)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "JHOUaZduYows"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features (X) and target (y)\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']"
      ],
      "metadata": {
        "id": "XKpLaqK_doi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split: Train-test split allows us to evaluate how well our model is likely to perform on unseen data.\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "hQQTizRrd9Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature scaling/ Standardizing the data:\n",
        "# Many machine learning models work better when all input features (columns) are on a similar scale.\n",
        "# Without scaling, features with larger values can dominate the learning process and confuse the model.\n",
        "\n",
        "#\n",
        "# Think of this like adjusting different lab measurements to the same unit scale.\n",
        "# For example, if one feature is blood pressure and another is glucose level, they have different units.\n",
        "# StandardScaler makes all features \"comparable\" by bringing them to the same scale (mean = 0, std = 1).\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "ig4x2o14eBCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Model Selection and Training\n",
        "Model: a machine learning model is a tool that learns patterns from data and makes predictions. You give it patient data (like blood pressure, glucose level, etc.), and it learns how to predict whether someone may have diabetes.\n",
        "\n",
        "*Here, we are solving a binary classification problem using Logistic Regression and Decision Trees.*\n",
        "\n",
        "- Logistic Regression: is a model that estimates the probability of a class using a logistic function, best suited for simple, linearly separable data.\n",
        "\n",
        "- Decision Tree:  is a non-linear model that splits data into branches based on feature values, easy to interpret for complex patterns. Handles non-linear patterns, more intuitive.\n",
        "\n",
        "Note: Choosing the right machine learning model depends on your data type, the problem you're solving (classification, regression, etc.), the size and quality of your dataset. There's no one-size-fits-all—it's often about trying a few models and comparing their performance.\n",
        "\n",
        "Model Training: Training is equivalent to teaching the model using examples.\n",
        "A model looks at many data samples and learns to \"understand\" patterns.\n",
        "\n",
        "\n",
        "https://colab.research.google.com/drive/1PtoFXpdx7jml4Q1oBKMgcOqKQFDSFoD8?usp=sharing"
      ],
      "metadata": {
        "id": "q-gaHm5nS6Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: Logistic Regression, Predicts probabilities (like disease present or not)\n",
        "\n",
        "# Logistic regression is a supervised machine learning algorithm that accomplishes binary\n",
        "# classification tasks by predicting the probability of an outcome, event, or observation.\n",
        "# The model delivers a binary outcome limited to two possible outcomes: yes/no, 0/1, or true/false.\n",
        "\n",
        "log_model = LogisticRegression()\n",
        "log_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "#fit identifies the model parameters that minimizes the loss"
      ],
      "metadata": {
        "id": "8I4DrMBBeDcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: Decision Tree, Follows a series of questions to make a decision.\n",
        "tree_model = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
        "tree_model.fit(X_train, y_train)\n",
        "#tree_model.plot_decision_boundary(X_train, y_train)"
      ],
      "metadata": {
        "id": "FbGaywvrTLui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree Plot\n",
        "#from sklearn.tree import plot_tree\n",
        "#plt.figure(figsize=(12, 8))\n",
        "#plot_tree(tree_model, max_depth=2, filled=True, feature_names=X_train.columns, class_names=[\"No Diabetes\", \"Diabetes\"])\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "yHVGxUTHeFmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Model Evaluation\n"
      ],
      "metadata": {
        "id": "gnrFn-cgTZjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model evaluation/predictions\n",
        "\n",
        "# Making predictions on new (unseen) data:\n",
        "# Now that the model has learned from training data, we ask it to predict whether a person has diabetes or not,\n",
        "# based on their health measurements in the test set.\n",
        "\n",
        "def evaluate(model, X_test, y_test, title):\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\n--- {title} ---\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
        "    plt.title(f\"Confusion Matrix - {title}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oYW_TGNkeI24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models\n",
        "evaluate(log_model, X_test_scaled, y_test, \"Logistic Regression\")\n",
        "evaluate(tree_model, X_test, y_test, \"Decision Tree\")\n"
      ],
      "metadata": {
        "id": "R5pmgN8neQoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the ROC Curve:\n",
        "# This curve helps us see how well our model separates diabetic from non-diabetic cases.\n",
        "# Think of it like checking how good a medical test is at correctly identifying sick and healthy patients.\n",
        "\n",
        "y_prob_log = log_model.predict_proba(X_test_scaled)[:, 1]\n",
        "y_prob_tree = tree_model.predict_proba(X_test)[:, 1]\n"
      ],
      "metadata": {
        "id": "yQbxcTDKeROr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr_log, tpr_log, _ = roc_curve(y_test, y_prob_log)\n",
        "fpr_tree, tpr_tree, _ = roc_curve(y_test, y_prob_tree)"
      ],
      "metadata": {
        "id": "Ekak7Gakeb5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(fpr_log, tpr_log, label=f'Logistic Regression (AUC = {auc(fpr_log, tpr_log):.2f}')\n",
        "plt.plot(fpr_tree, tpr_tree, label=f'Decision Tree (AUC = {auc(fpr_tree, tpr_tree):.2f}')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SVTMloVIef8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Check your understanding\n"
      ],
      "metadata": {
        "id": "HsRMn-BXT6V5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding Metrics in `classification_report`\n",
        "\n",
        "The `classification_report` in scikit-learn provides key metrics to evaluate classification model performance.\n",
        "\n",
        "---\n",
        "\n",
        "| **Metric**      | **Explanation**                                                                 |\n",
        "|-----------------|----------------------------------------------------------------------------------|\n",
        "| **Precision**   | Of all predicted positives, how many were actually positive? <br> **Precision = TP / (TP + FP)** <br>→ Measures how accurate positive predictions are |\n",
        "| **Recall**      | Of all actual positives, how many were correctly predicted? <br> **Recall = TP / (TP + FN)** <br>→ Measures how well the model captures actual positives |\n",
        "| **F1-score**    | Harmonic mean of precision and recall <br> **F1 = 2 × (Precision × Recall) / (Precision + Recall)** <br>→ Balances both precision and recall         |\n",
        "| **Support**     | Number of actual instances for each class in the dataset                           |\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "### Additional Metrics:\n",
        "\n",
        "| **Metric**        | **Explanation**                                                                 |\n",
        "|-------------------|----------------------------------------------------------------------------------|\n",
        "| **Accuracy**       | Overall, how many predictions were correct:<br>`(TP + TN) / Total Samples`      |\n",
        "| **Macro Avg**      | Average of precision/recall/F1 across classes (all classes treated equally)     |\n",
        "| **Weighted Avg**   | Average weighted by class support (more influenced by majority class)           |\n",
        "\n",
        "---\n",
        "\n",
        "### When to Use Which?\n",
        "- Use **Recall** when missing positives is risky (e.g., disease detection)\n",
        "- Use **Precision** when false alarms are costly\n",
        "- Use **F1-score** for balance between Precision and Recall\n",
        "- Use **Macro Avg** for imbalanced data (equal class importance)\n",
        "- Use **Weighted Avg** to reflect performance based on class distribution\n",
        "\n"
      ],
      "metadata": {
        "id": "4kIXe1gFlcl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Diabetes ML Quiz with Answers and Explanations\n",
        "\n",
        "print(\"Diabetes ML Quiz – Type a, b, c, or d to answer. You'll get explanations after each question!\\n\")\n",
        "\n",
        "print(\"\\n--- Dataset Understanding ---\")\n",
        "\n",
        "# Question 1\n",
        "ans = input(\"1. What does each row in the dataset represent?\\n(a) A patient\\n(b) A hospital\\n(c) A test result\\n(d) A machine learning model\\nYour answer: \")\n",
        "if ans.lower() == 'a':\n",
        "    print(\"Correct! Each row is one patient’s medical data.\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (a). Each row represents one patient.\")\n",
        "\n",
        "# Question 2\n",
        "ans = input(\"\\n2. What does the target column 'Outcome' represent?\\n(a) The type of diabetes\\n(b) Whether a person has diabetes or not\\n(c) Glucose levels\\n(d) Age group\\nYour answer: \")\n",
        "if ans.lower() == 'b':\n",
        "    print(\"Correct! Outcome is 1 if the person has diabetes, 0 if not.\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (b).\")\n",
        "\n",
        "print(\"\\n--- Model Training and Evaluation ---\")\n",
        "\n",
        "# Question 3\n",
        "ans = input(\"\\n3. Why do we use StandardScaler?\\n(a) To normalize text\\n(b) To improve plot visibility\\n(c) To bring all features to the same scale\\n(d) To remove missing values\\nYour answer: \")\n",
        "if ans.lower() == 'c':\n",
        "    print(\"Correct! Scaling helps models treat all features equally.\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (c).\")\n",
        "\n",
        "# Question 4\n",
        "ans = input(\"\\n4. Which models did we use to classify diabetes?\\n(a) Logistic Regression\\n(b) Decision Tree\\n(c) Random Forest\\n(d) a and b\\nYour answer: \")\n",
        "if ans.lower() == 'd':\n",
        "    print(\"Correct! We trained Logistic Regression and Decision Tree models.\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (d).\")\n",
        "\n",
        "# Question 5\n",
        "ans = input(\"\\n5. What does the confusion matrix show us?\\n(a) The training accuracy\\n(b) A visual of correct and incorrect predictions\\n(c) The data distribution\\n(d) The model structure\\nYour answer: \")\n",
        "if ans.lower() == 'b':\n",
        "    print(\"Correct! It shows where the model is right and where it made mistakes.\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (b).\")\n",
        "\n",
        "# Question 6\n",
        "ans = input(\"\\n6. What is the purpose of the ROC curve?\\n(a) To detect outliers\\n(b) To plot feature importance\\n(c) To evaluate model’s ability to separate classes\\n(d) To train the model\\nYour answer: \")\n",
        "if ans.lower() == 'c':\n",
        "    print(\"Correct! It shows how well the model distinguishes between classes.\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (c).\")\n",
        "\n",
        "# Question 7\n",
        "ans = input(\"\\n7. What would the model output for a new patient’s data?\\n(a) A probability of having diabetes\\n(b) A diagnosis report\\n(c) A pie chart\\n(d) A list of symptoms\\nYour answer: \")\n",
        "if ans.lower() == 'a':\n",
        "    print(\"Correct! Most models give a probability score between 0 and 1.\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (a).\")\n",
        "\n",
        "\n",
        "# Additional ML Concepts Questions\n",
        "print(\"\\n--- General ML Concepts ---\")\n",
        "\n",
        "# Q8: What is a model?\n",
        "ans = input(\"\\n8. What is a model in Machine Learning?\\n(a) A program that stores data\\n(b) A trained function that makes predictions\\n(c) A file that holds images\\n(d) A neural network only\\nYour answer: \")\n",
        "if ans.lower() == 'b':\n",
        "    print(\"Correct! A model is a trained function that learns from data and makes predictions.\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (b). A model is a trained function that can predict based on input features.\")\n",
        "\n",
        "# Q9: What does 'training a model' mean?\n",
        "ans = input(\"\\n9. What does 'training a model' mean?\\n(a) Installing ML libraries\\n(b) Typing Python code\\n(c) Finding patterns in data to make predictions\\n(d) Testing accuracy\\nYour answer: \")\n",
        "if ans.lower() == 'c':\n",
        "    print(\"Correct! Training means the model learns patterns from the training data.\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (c).\")\n",
        "\n",
        "# Q10: Why do we split data into training and testing sets?\n",
        "ans = input(\"\\n10. Why do we split data into training and testing sets?\\n(a) To reduce dataset size\\n(b) To test computer speed\\n(c) To check if the model works well on new/unseen data\\n(d) To improve accuracy only\\nYour answer: \")\n",
        "if ans.lower() == 'c':\n",
        "    print(\"Correct! The test set helps us evaluate how the model performs on new, unseen data.\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (c).\")\n",
        "\n",
        "# Q11: Which of the following best describes the major steps in an ML pipeline?\n",
        "ans = input(\"\\n11. Which of these is the correct order of ML steps?\\n(a) Train → Collect Data → Predict → Clean\\n(b) Collect Data → Clean → Train → Evaluate → Predict\\n(c) Install Python → Collect Data → Predict → Save\\n(d) Predict → Clean → Evaluate\\nYour answer: \")\n",
        "if ans.lower() == 'b':\n",
        "    print(\"Correct! This is the usual pipeline followed in ML projects.\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (b).\")\n",
        "\n",
        "#More Questions\n",
        "# Question 12\n",
        "ans = input(\"\\n12. A classifier gives high accuracy but performs poorly on the minority class. What might be happening?\\n(a) The dataset is balanced\\n(b) The model has high precision and recall\\n(c) The dataset is imbalanced, and the model favors the majority class\\n(d) Accuracy always reflects balanced performance\\nYour answer: \")\n",
        "if ans.lower() == 'c':\n",
        "    print(\"Correct! High accuracy can be misleading in imbalanced datasets where the model mostly predicts the majority class.\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (c). In imbalanced datasets, accuracy may hide poor performance on the minority class.\")\n",
        "\n",
        "print(\"\\n--- Imbalanced Data & Medical Relevance ---\")\n",
        "\n",
        "# Question 13\n",
        "ans = input(\"\\n13. If false negatives are more dangerous (e.g., in disease detection), which metric should you focus on?\\n(a) Precision\\n(b) Recall\\n(c) Accuracy\\n(d) F1-score\\nYour answer: \")\n",
        "if ans.lower() == 'b':\n",
        "    print(\"Correct! Recall is crucial when missing positive cases (false negatives) is risky, like in medical diagnoses.\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (b). Recall helps minimize false negatives.\")\n",
        "\n",
        "# Question 14: Which metric to prioritize in disease detection?\n",
        "ans = input(\"\\n14. In disease detection, which metric is usually most important?\\n(a) Precision\\n(b) Recall\\n(c) F1-score\\n(d) Accuracy\\nYour answer: \")\n",
        "if ans.lower() == 'b':\n",
        "    print(\"Correct! Recall is crucial to avoid missing patients who actually have the disease (false negatives).\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (b). Recall helps us detect as many actual cases as possible.\")\n",
        "\n",
        "# Question 15\n",
        "ans = input(\"\\n15. In an imbalanced dataset (e.g., 90% negative, 10% positive), which model is likely misleading?\\n(a) A model with 90% accuracy\\n(b) A model with 80% recall\\n(c) A model with high F1-score\\n(d) A model with good precision\\nYour answer: \")\n",
        "if ans.lower() == 'a':\n",
        "    print(\"Correct! A model predicting only the majority class can still get 90% accuracy but completely miss the minority class.\")\n",
        "else:\n",
        "    print(\"Incorrect. The correct answer is (a). High accuracy can be misleading in imbalanced datasets.\")\n",
        "\n",
        "# Question 16\n",
        "# ans = input(\"\\n16. Which model might be better suited to handle imbalanced data directly?\\n(a) Logistic Regression without any changes\\n(b) Decision Tree with class_weight='balanced'\\n(c) KMeans clustering\\n(d) Linear Regression\\nYour answer: \")\n",
        "# if ans.lower() == 'b':\n",
        "#     print(\"Correct! Decision Trees (and many sklearn models) can be configured with class_weight='balanced' to better handle imbalance.\")\n",
        "# else:\n",
        "#     print(\"Incorrect. The correct answer is (b). Using class_weight='balanced' helps focus on minority classes.\")"
      ],
      "metadata": {
        "id": "4m-Zs4TKhPwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#End"
      ],
      "metadata": {
        "id": "f6xHe2t3hmDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6lgUYD8NvLEv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}